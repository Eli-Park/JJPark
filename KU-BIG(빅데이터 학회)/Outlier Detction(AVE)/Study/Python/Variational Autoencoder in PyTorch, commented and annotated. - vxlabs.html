<!DOCTYPE html>
<!-- saved from url=(0089)https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Variational Autoencoder in PyTorch, commented and annotated. - vxlabs</title>
  <meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="cpbotha"><meta name="description" content="I have recently become fascinated with (Variational) Autoencoders and with PyTorch.
Kevin Frans has a beautiful blog post online explaining variational autoencoders, with examples in TensorFlow and, importantly, with cat pictures. Jaan Altosaar&amp;#8217;s blog post takes an even deeper look at VAEs from both the deep learning perspective and the perspective of graphical models. Both of these posts, as well as Diederik Kingma&amp;#8217;s original 2014 paper Auto-Encoding Variational Bayes, are more than worth your time.">






<meta name="generator" content="Hugo 0.55.5 with even 4.0.0">


<link rel="canonical" href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/">
<link rel="apple-touch-icon" sizes="180x180" href="https://vxlabs.com/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://vxlabs.com/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://vxlabs.com/favicon-16x16.png">
<link rel="manifest" href="https://vxlabs.com/manifest.json">
<link rel="mask-icon" href="https://vxlabs.com/safari-pinned-tab.svg" color="#5bbad5">


<link href="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/even.c2a46f00.min.css" rel="stylesheet">

<link rel="stylesheet" href="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/vxl-custom-even.css">


<meta property="og:title" content="Variational Autoencoder in PyTorch, commented and annotated.">
<meta property="og:description" content="I have recently become fascinated with (Variational) Autoencoders and with PyTorch.
Kevin Frans has a beautiful blog post online explaining variational autoencoders, with examples in TensorFlow and, importantly, with cat pictures. Jaan Altosaar’s blog post takes an even deeper look at VAEs from both the deep learning perspective and the perspective of graphical models. Both of these posts, as well as Diederik Kingma’s original 2014 paper Auto-Encoding Variational Bayes, are more than worth your time.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/">
<meta property="article:published_time" content="2017-12-08T08:43:00+00:00">
<meta property="article:modified_time" content="2017-12-08T08:43:00+00:00">

<meta itemprop="name" content="Variational Autoencoder in PyTorch, commented and annotated.">
<meta itemprop="description" content="I have recently become fascinated with (Variational) Autoencoders and with PyTorch.
Kevin Frans has a beautiful blog post online explaining variational autoencoders, with examples in TensorFlow and, importantly, with cat pictures. Jaan Altosaar’s blog post takes an even deeper look at VAEs from both the deep learning perspective and the perspective of graphical models. Both of these posts, as well as Diederik Kingma’s original 2014 paper Auto-Encoding Variational Bayes, are more than worth your time.">


<meta itemprop="datePublished" content="2017-12-08T08:43:00+00:00">
<meta itemprop="dateModified" content="2017-12-08T08:43:00+00:00">
<meta itemprop="wordCount" content="2042">



<meta itemprop="keywords" content="autoencoders,deep learning,neural networks,pytorch,variational autoencoders,">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Variational Autoencoder in PyTorch, commented and annotated.">
<meta name="twitter:description" content="I have recently become fascinated with (Variational) Autoencoders and with PyTorch.
Kevin Frans has a beautiful blog post online explaining variational autoencoders, with examples in TensorFlow and, importantly, with cat pictures. Jaan Altosaar’s blog post takes an even deeper look at VAEs from both the deep learning perspective and the perspective of graphical models. Both of these posts, as well as Diederik Kingma’s original 2014 paper Auto-Encoding Variational Bayes, are more than worth your time.">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

<style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style id="isso-style" type="text/css">#isso-thread * {
    -webkit-box-sizing: border-box;
    -moz-box-sizing: border-box;
    box-sizing: border-box;
}
#isso-thread .isso-comment-header a {
    text-decoration: none;
}

#isso-thread {
    padding: 0;
    margin: 0;
}
#isso-thread > h4 {
    color: #555;
    font-weight: bold;
}
#isso-thread > .isso-feedlink {
    float: right;
    padding-left: 1em;
}
#isso-thread > .isso-feedlink > a {
    font-size: 0.8em;
    vertical-align: bottom;
}
#isso-thread .textarea {
    min-height: 58px;
    outline: 0;
}
#isso-thread .textarea.placeholder {
    color: #757575;
}

#isso-root .isso-comment {
    max-width: 68em;
    padding-top: 0.95em;
    margin: 0.95em auto;
}
#isso-root .preview .isso-comment {
    padding-top: 0;
    margin: 0;
}
#isso-root .isso-comment:not(:first-of-type),
.isso-follow-up .isso-comment {
    border-top: 1px solid rgba(0, 0, 0, 0.1);
}
.isso-comment > div.avatar {
    display: block;
    float: left;
    width: 7%;
    margin: 3px 15px 0 0;
}
.isso-comment > div.avatar > svg {
    max-width: 48px;
    max-height: 48px;
    border: 1px solid rgba(0, 0, 0, 0.2);
    border-radius: 3px;
    box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
}
.isso-comment > div.text-wrapper {
    display: block;
}
.isso-comment .isso-follow-up {
    padding-left: calc(7% + 20px);
}
.isso-comment > div.text-wrapper > .isso-comment-header, .isso-comment > div.text-wrapper > .isso-comment-footer {
    font-size: 0.95em;
}
.isso-comment > div.text-wrapper > .isso-comment-header {
    font-size: 0.85em;
}
.isso-comment > div.text-wrapper > .isso-comment-header .spacer {
    padding: 0 6px;
}
.isso-comment > div.text-wrapper > .isso-comment-header .spacer,
.isso-comment > div.text-wrapper > .isso-comment-header a.permalink,
.isso-comment > div.text-wrapper > .isso-comment-header .note,
.isso-comment > div.text-wrapper > .isso-comment-header a.parent {
    color: gray !important;
    font-weight: normal;
    text-shadow: none !important;
}
.isso-comment > div.text-wrapper > .isso-comment-header .spacer:hover,
.isso-comment > div.text-wrapper > .isso-comment-header a.permalink:hover,
.isso-comment > div.text-wrapper > .isso-comment-header .note:hover,
.isso-comment > div.text-wrapper > .isso-comment-header a.parent:hover {
    color: #606060 !important;
}
.isso-comment > div.text-wrapper > .isso-comment-header .note {
    float: right;
}
.isso-comment > div.text-wrapper > .isso-comment-header .author {
    font-weight: bold;
    color: #555;
}
.isso-comment > div.text-wrapper > .textarea-wrapper .textarea,
.isso-comment > div.text-wrapper > .textarea-wrapper .preview {
    margin-top: 0.2em;
}
.isso-comment > div.text-wrapper > div.text p {
    margin-top: 0.2em;
}
.isso-comment > div.text-wrapper > div.text p:last-child {
    margin-bottom: 0.2em;
}
.isso-comment > div.text-wrapper > div.text h1,
.isso-comment > div.text-wrapper > div.text h2,
.isso-comment > div.text-wrapper > div.text h3,
.isso-comment > div.text-wrapper > div.text h4,
.isso-comment > div.text-wrapper > div.text h5,
.isso-comment > div.text-wrapper > div.text h6 {
    font-size: 130%;
    font-weight: bold;
}
.isso-comment > div.text-wrapper > div.textarea-wrapper .textarea,
.isso-comment > div.text-wrapper > div.textarea-wrapper .preview {
    width: 100%;
    border: 1px solid #f0f0f0;
    border-radius: 2px;
    box-shadow: 0 0 2px #888;
}
.isso-comment > div.text-wrapper > .isso-comment-footer {
    font-size: 0.80em;
    color: gray !important;
    clear: left;
}
.isso-feedlink,
.isso-comment > div.text-wrapper > .isso-comment-footer a {
    font-weight: bold;
    text-decoration: none;
}
.isso-feedlink:hover,
.isso-comment > div.text-wrapper > .isso-comment-footer a:hover {
    color: #111111 !important;
    text-shadow: #aaaaaa 0 0 1px !important;
}
.isso-comment > div.text-wrapper > .isso-comment-footer > a {
    position: relative;
    top: .2em;
}
.isso-comment > div.text-wrapper > .isso-comment-footer > a + a {
    padding-left: 1em;
}
.isso-comment > div.text-wrapper > .isso-comment-footer .votes {
    color: gray;
}
.isso-comment > div.text-wrapper > .isso-comment-footer .upvote svg,
.isso-comment > div.text-wrapper > .isso-comment-footer .downvote svg {
    position: relative;
    top: .2em;
}
.isso-comment .isso-postbox {
    margin-top: 0.8em;
}
.isso-comment.isso-no-votes span.votes {
    display: none;
}

.isso-postbox {
    max-width: 68em;
    margin: 0 auto 2em;
    clear: right;
}
.isso-postbox > .form-wrapper {
    display: block;
    padding: 0;
}
.isso-postbox > .form-wrapper > .auth-section,
.isso-postbox > .form-wrapper > .auth-section .post-action {
    display: block;
}
.isso-postbox > .form-wrapper .textarea,
.isso-postbox > .form-wrapper .preview {
    margin: 0 0 .3em;
    padding: .4em .8em;
    border-radius: 3px;
    background-color: #fff;
    border: 1px solid rgba(0, 0, 0, 0.2);
    box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
}
.isso-postbox > .form-wrapper input[type=checkbox] {
    vertical-align: middle;
    position: relative;
    bottom: 1px;
    margin-left: 0;
}
.isso-postbox > .form-wrapper .notification-section {
    font-size: 0.90em;
    padding-top: .3em;
}
#isso-thread .textarea:focus,
#isso-thread input:focus {
    border-color: rgba(0, 0, 0, 0.8);
}
.isso-postbox > .form-wrapper > .auth-section .input-wrapper {
    display: inline-block;
    position: relative;
    max-width: 25%;
    margin: 0;
}
.isso-postbox > .form-wrapper > .auth-section .input-wrapper input {
    padding: .3em 10px;
    max-width: 100%;
    border-radius: 3px;
    background-color: #fff;
    line-height: 1.4em;
    border: 1px solid rgba(0, 0, 0, 0.2);
    box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
}
.isso-postbox > .form-wrapper > .auth-section .post-action {
    display: inline-block;
    float: right;
    margin: 0 0 0 5px;
}
.isso-postbox > .form-wrapper > .auth-section .post-action > input {
    padding: calc(.3em - 1px);
    border-radius: 2px;
    border: 1px solid #CCC;
    background-color: #DDD;
    cursor: pointer;
    outline: 0;
    line-height: 1.4em;
    box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
}
.isso-postbox > .form-wrapper > .auth-section .post-action > input:hover {
    background-color: #CCC;
}
.isso-postbox > .form-wrapper > .auth-section .post-action > input:active {
    background-color: #BBB;
}
.isso-postbox > .form-wrapper .preview,
.isso-postbox > .form-wrapper input[name="edit"],
.isso-postbox.preview-mode > .form-wrapper input[name="preview"],
.isso-postbox.preview-mode > .form-wrapper .textarea {
    display: none;
}
.isso-postbox.preview-mode > .form-wrapper .preview {
    display: block;
}
.isso-postbox.preview-mode > .form-wrapper input[name="edit"] {
    display: inline;
}
.isso-postbox > .form-wrapper .preview {
    background-color: #f8f8f8;
    background: repeating-linear-gradient(
        -45deg,
        #f8f8f8,
        #f8f8f8 10px,
        #fff 10px,
        #fff 20px
    );
}
.isso-postbox > .form-wrapper > .notification-section {
    display: none;
    padding-bottom: 10px;
}
@media screen and (max-width:600px) {
    .isso-postbox > .form-wrapper > .auth-section .input-wrapper {
        display: block;
        max-width: 100%;
        margin: 0 0 .3em;
    }
    .isso-postbox > .form-wrapper > .auth-section .input-wrapper input {
        width: 100%;
    }
}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
<body><div id="MathJax_Message" style="display: none;"></div>
  
<div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="https://vxlabs.com/" class="logo">
      <img style="height: 36px;" src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/vxlabs_logo_h_240.png" alt="vxlabs - visualization, imaging &amp; software engineering">
    </a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu slideout-menu-left">
  <ul class="mobile-menu-list">
    <a href="https://vxlabs.com/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="https://vxlabs.com/subscribe/">
        <li class="mobile-menu-item">Subscribe</li>
      </a>
  </ul>
</nav>
  <div class="container slideout-panel slideout-panel-left" id="mobile-panel">
    <header id="header" class="header">
        
<div class="logo-wrapper">
  <a href="https://vxlabs.com/" class="logo">
    <img style="height: 56px;" src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/vxlabs_logo_h_240.png" alt="vxlabs - visualization, imaging &amp; software engineering">
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="https://vxlabs.com/about/">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://vxlabs.com/subscribe/">Subscribe</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Variational Autoencoder in PyTorch, commented and annotated.</h1>

      <div class="post-meta">
        <span class="post-time"> 2017-12-08 </span>
        <div class="post-category">
            <a href="https://vxlabs.com/categories/howto/"> howto </a>
            </div>
          <span class="more-meta"> 2042 words </span>
          <span class="more-meta"> 10 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#what-is-pytorch" class=" toc-link">What is PyTorch?</a></li>
<li><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#what-is-an-autoencoder" class=" toc-link">What is an autoencoder?</a></li>
<li><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#what-is-a-variational-autoencoder" class=" toc-link">What is a variational autoencoder?</a></li>
<li><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#results-using-mnist" class=" toc-link">Results using MNIST</a></li>
<li><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#a-diagram-of-a-simple-vae" class=" toc-link">A diagram of a simple VAE</a></li>
<li><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#a-simple-vae-implemented-using-pytorch" class=" toc-link">A simple VAE implemented using PyTorch</a></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      

<p>I have recently become fascinated with (Variational) Autoencoders and with PyTorch.</p>

<p>Kevin Frans has <a href="http://kvfrans.com/variational-autoencoders-explained/">a beautiful blog post</a> online explaining variational
autoencoders, with examples in TensorFlow and, importantly, with cat
pictures. Jaan Altosaar’s <a href="https://jaan.io/what-is-variational-autoencoder-vae-tutorial/">blog post</a> takes an even deeper look at
VAEs from both the deep learning perspective and the perspective of graphical
models. Both of these posts, as well as Diederik Kingma’s <a href="https://arxiv.org/pdf/1312.6114.pdf">original 2014
paper</a> <em>Auto-Encoding Variational Bayes</em>, are more than worth your time.</p>

<p>In my case, I wanted to understand VAEs from the perspective of a PyTorch
implementation. I started with the <a href="https://github.com/pytorch/examples/blob/master/vae/main.py">VAE example</a> on the PyTorch github,
adding explanatory comments and Python type annotations as I was working my
way through it.</p>

<p>This post summarises my understanding, and contains my commented and annotated
version of the PyTorch VAE example. I hope it helps!</p>

<h1 id="what-is-pytorch"><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#what-is-pytorch" class="headerlink anchor"><i class="iconfont icon-link"></i></a>What is PyTorch?</h1>

<p><a href="http://pytorch.org/">PyTorch</a> is FAIR’s (that’s Facebook AI Research) Python dynamic deep learning / neural network library. The way that FAIR has managed to make neural network experimentation so dynamic and so natural is nothing short of miraculous. Read <a href="http://www.fast.ai/2017/09/08/introducing-pytorch-for-fastai/">this post by fast.ai</a> to find out more about their reasons for excitement, many of which I share.</p>

<h1 id="what-is-an-autoencoder"><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#what-is-an-autoencoder" class="headerlink anchor"><i class="iconfont icon-link"></i></a>What is an autoencoder?</h1>

<p>The general idea of the autoencoder (AE) is to squeeze information through a narrow bottleneck between the mirrored encoder (input) and decoder (output) parts of a neural network. (see the diagram below)</p>

<p>Because the network achitecture and loss function are setup so that the output tries to emulate the input, the network has to learn how to encode input data on the very limited space represented by the bottleneck.</p>

<h1 id="what-is-a-variational-autoencoder"><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#what-is-a-variational-autoencoder" class="headerlink anchor"><i class="iconfont icon-link"></i></a>What is a variational autoencoder?</h1>

<p>Variational Autoencoders, or VAEs, are an extension of AEs that additionally force the network to ensure that samples are normally distributed over the space represented by the bottleneck.</p>

<p>They do this by having the encoder output two <code>n</code>-dimensional (where <code>n</code> is the number of dimensions in the latent space) vectors representing the mean and the standard devation. These Gaussians are sampled, and <i>the samples are sent through the decoder</i>. This is the reparameterization step, also see my comments in the <code>reparameterize()</code> function.</p>

<p>What a fabulous trick!</p>

<p>The loss function has a term for input-output similarity, and, importantly, it has a second term that uses the Kullback–Leibler divergence to test how close the learned Gaussians are to unit Gaussians.</p>

<p>In other words, this extension to AEs enables us to derive Gaussian
distributed latent spaces from arbitrary data. Given for example a large set
of shapes, the latest space would be a high-dimensional space where each shape
is represented by a single point, and the points would be normally distributed
over all dimensions. With this one can represent existing shapes, but one can
also synthesise completely new and plausible shapes by sampling points in
latent space.</p>

<h1 id="results-using-mnist"><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#results-using-mnist" class="headerlink anchor"><i class="iconfont icon-link"></i></a>Results using MNIST</h1>

<p>Below you see 64 random samples of a two-dimensional latent space of MNIST digits that I made with the example below, with <code>ZDIMS=2</code>.</p>

<p><img src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/pytorch-vae-sample-z2-epoch10.png" alt="pytorch-vae-sample-z2-epoch10.png" data-recalc-dims="1"></p>

<p>Next is the reconstruction of 8 random unseen test digits via a more reasonable 20-dimensional latent space. Keep in mind that the VAE has learned a 20-dimensional normal distribution for any input digit, from which samples are drawn that reconstruct via the decoder to output that appear similar to the input.</p>

<p><img src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/pytorch-vae-reconstruction-z10-epoch10.png" alt="pytorch-vae-reconstruction-z10-epoch10.png" data-recalc-dims="1"></p>

<h1 id="a-diagram-of-a-simple-vae"><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#a-diagram-of-a-simple-vae" class="headerlink anchor"><i class="iconfont icon-link"></i></a>A diagram of a simple VAE</h1>

<p>An example VAE, incidentally also the one implemented in the PyTorch code below, looks like this:</p>

<p><a href="https://vxlabs.com/wp-content/uploads/2017/12/pytorch-vae-arch-2.png?ssl=1"><img src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/pytorch-vae-arch-2.png" alt="pytorch-vae-arch-2.png" data-recalc-dims="1"></a></p>

<h1 id="a-simple-vae-implemented-using-pytorch"><a href="https://vxlabs.com/2017/12/08/variational-autoencoder-in-pytorch-commented-and-annotated/#a-simple-vae-implemented-using-pytorch" class="headerlink anchor"><i class="iconfont icon-link"></i></a>A simple VAE implemented using PyTorch</h1>

<p>I used PyCharm in remote interpreter mode, with the interpreter running on a machine with a CUDA-capable GPU to explore the code below. PyCharm parses the type annotations, which helps with code completion. I also made extensive use of the debugger to better understand logic flow and variable contents. (Debuggability is one of PyTorch’s strong points.)</p>
<div class="highlight"><div class="chroma language-python">
<table class="lntable"><tbody><tr><td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span><span class="lnt">190
</span><span class="lnt">191
</span><span class="lnt">192
</span><span class="lnt">193
</span><span class="lnt">194
</span><span class="lnt">195
</span><span class="lnt">196
</span><span class="lnt">197
</span><span class="lnt">198
</span><span class="lnt">199
</span><span class="lnt">200
</span><span class="lnt">201
</span><span class="lnt">202
</span><span class="lnt">203
</span><span class="lnt">204
</span><span class="lnt">205
</span><span class="lnt">206
</span><span class="lnt">207
</span><span class="lnt">208
</span><span class="lnt">209
</span><span class="lnt">210
</span><span class="lnt">211
</span><span class="lnt">212
</span><span class="lnt">213
</span><span class="lnt">214
</span><span class="lnt">215
</span><span class="lnt">216
</span><span class="lnt">217
</span><span class="lnt">218
</span><span class="lnt">219
</span><span class="lnt">220
</span><span class="lnt">221
</span><span class="lnt">222
</span><span class="lnt">223
</span><span class="lnt">224
</span><span class="lnt">225
</span><span class="lnt">226
</span><span class="lnt">227
</span><span class="lnt">228
</span><span class="lnt">229
</span><span class="lnt">230
</span><span class="lnt">231
</span><span class="lnt">232
</span><span class="lnt">233
</span><span class="lnt">234
</span><span class="lnt">235
</span><span class="lnt">236
</span><span class="lnt">237
</span><span class="lnt">238
</span><span class="lnt">239
</span><span class="lnt">240
</span><span class="lnt">241
</span><span class="lnt">242
</span><span class="lnt">243
</span><span class="lnt">244
</span><span class="lnt">245
</span><span class="lnt">246
</span><span class="lnt">247
</span><span class="lnt">248
</span><span class="lnt">249
</span><span class="lnt">250
</span><span class="lnt">251
</span><span class="lnt">252
</span><span class="lnt">253
</span><span class="lnt">254
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># example from https://github.com/pytorch/examples/blob/master/vae/main.py</span>
<span class="c1"># commented and type annotated by Charl Botha &lt;cpbotha@vxlabs.com&gt;</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">save_image</span>

<span class="c1"># changed configuration to this instead of argparse for easier interaction</span>
<span class="n">CUDA</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">LOG_INTERVAL</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># connections through the autoencoder bottleneck</span>
<span class="c1"># in the pytorch VAE example, this is 20</span>
<span class="n">ZDIMS</span> <span class="o">=</span> <span class="mi">20</span>

<span class="c1"># I do this so that the MNIST dataset is downloaded where I want it</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">"/home/cpbotha/Downloads/pytorch-vae"</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="k">if</span> <span class="n">CUDA</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># DataLoader instances will load tensors directly into GPU memory</span>
<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'num_workers'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'pin_memory'</span><span class="p">:</span> <span class="bp">True</span><span class="p">}</span> <span class="k">if</span> <span class="n">CUDA</span> <span class="k">else</span> <span class="p">{}</span>

<span class="c1"># Download or load downloaded MNIST dataset</span>
<span class="c1"># shuffle data at every epoch</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                   <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="c1"># Same for test data</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># ENCODER</span>
        <span class="c1"># 28 x 28 pixels = 784 input pixels, 400 outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="c1"># rectified linear unit layer from 400 to 400</span>
        <span class="c1"># max(0, x)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc21</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="n">ZDIMS</span><span class="p">)</span>  <span class="c1"># mu layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc22</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="n">ZDIMS</span><span class="p">)</span>  <span class="c1"># logvariance layer</span>
        <span class="c1"># this last layer bottlenecks through ZDIMS connections</span>

        <span class="c1"># DECODER</span>
        <span class="c1"># from bottleneck to hidden 400</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">ZDIMS</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
        <span class="c1"># from hidden 400 to 784 outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Variable</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>
        <span class="s2">"""Input vector x -&gt; fully connected 1 -&gt; ReLU -&gt; (fully connected
</span><span class="s2">        21, fully connected 22)
</span><span class="s2">
</span><span class="s2">        Parameters
</span><span class="s2">        ----------
</span><span class="s2">        x : [128, 784] matrix; 128 digits of 28x28 pixels each
</span><span class="s2">
</span><span class="s2">        Returns
</span><span class="s2">        -------
</span><span class="s2">
</span><span class="s2">        (mu, logvar) : ZDIMS mean units one for each latent dimension, ZDIMS
</span><span class="s2">            variance units one for each latent dimension
</span><span class="s2">
</span><span class="s2">        """</span>

        <span class="c1"># h1 is [128, 400]</span>
        <span class="n">h1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>  <span class="c1"># type: Variable</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc21</span><span class="p">(</span><span class="n">h1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc22</span><span class="p">(</span><span class="n">h1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">:</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">logvar</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span><span class="p">:</span>
        <span class="s2">"""THE REPARAMETERIZATION IDEA:
</span><span class="s2">
</span><span class="s2">        For each training sample (we get 128 batched at a time)
</span><span class="s2">
</span><span class="s2">        - take the current learned mu, stddev for each of the ZDIMS
</span><span class="s2">          dimensions and draw a random sample from that distribution
</span><span class="s2">        - the whole network is trained so that these randomly drawn
</span><span class="s2">          samples decode to output that looks like the input
</span><span class="s2">        - which will mean that the std, mu will be learned
</span><span class="s2">          *distributions* that correctly encode the inputs
</span><span class="s2">        - due to the additional KLD term (see loss_function() below)
</span><span class="s2">          the distribution will tend to unit Gaussians
</span><span class="s2">
</span><span class="s2">        Parameters
</span><span class="s2">        ----------
</span><span class="s2">        mu : [128, ZDIMS] mean matrix
</span><span class="s2">        logvar : [128, ZDIMS] variance matrix
</span><span class="s2">
</span><span class="s2">        Returns
</span><span class="s2">        -------
</span><span class="s2">
</span><span class="s2">        During training random sample from the learned ZDIMS-dimensional
</span><span class="s2">        normal distribution; during inference its mean.
</span><span class="s2">
</span><span class="s2">        """</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="c1"># multiply log variance with 0.5, then in-place exponent</span>
            <span class="c1"># yielding the standard deviation</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">logvar</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">exp_</span><span class="p">()</span>  <span class="c1"># type: Variable</span>
            <span class="c1"># - std.data is the [128,ZDIMS] tensor that is wrapped by std</span>
            <span class="c1"># - so eps is [128,ZDIMS] with all elements drawn from a mean 0</span>
            <span class="c1">#   and stddev 1 normal distribution that is 128 samples</span>
            <span class="c1">#   of random ZDIMS-float vectors</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">std</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">std</span><span class="o">.</span><span class="n">size</span><span class="p">())</span><span class="o">.</span><span class="n">normal_</span><span class="p">())</span>
            <span class="c1"># - sample from a normal distribution with standard</span>
            <span class="c1">#   deviation = std and mean = mu by multiplying mean 0</span>
            <span class="c1">#   stddev 1 sample with desired std and mu, see</span>
            <span class="c1">#   https://stats.stackexchange.com/a/16338</span>
            <span class="c1"># - so we have 128 sets (the batch) of random ZDIMS-float</span>
            <span class="c1">#   vectors sampled from normal distribution with learned</span>
            <span class="c1">#   std and mu for the current input</span>
            <span class="k">return</span> <span class="n">eps</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># During inference, we simply spit out the mean of the</span>
            <span class="c1"># learned distribution for the current input.  We could</span>
            <span class="c1"># use a random sample from the distribution, but mu of</span>
            <span class="c1"># course has the highest probability.</span>
            <span class="k">return</span> <span class="n">mu</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span><span class="p">:</span>
        <span class="n">h3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">h3</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Variable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Variable</span><span class="p">,</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">()</span>
<span class="k">if</span> <span class="n">CUDA</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Variable</span><span class="p">:</span>
    <span class="c1"># how well do input x and output recon_x agree?</span>
    <span class="n">BCE</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>

    <span class="c1"># KLD is Kullback–Leibler divergence -- how much does one learned</span>
    <span class="c1"># distribution deviate from another, in this specific case the</span>
    <span class="c1"># learned distribution from the unit Gaussian</span>

    <span class="c1"># see Appendix B from VAE paper:</span>
    <span class="c1"># Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014</span>
    <span class="c1"># https://arxiv.org/abs/1312.6114</span>
    <span class="c1"># - D_{KL} = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)</span>
    <span class="c1"># note the negative D_{KL} in appendix B of the paper</span>
    <span class="n">KLD</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="nb">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
    <span class="c1"># Normalise by same number of elements as in reconstruction</span>
    <span class="n">KLD</span> <span class="o">/=</span> <span class="n">BATCH_SIZE</span> <span class="o">*</span> <span class="mi">784</span>

    <span class="c1"># BCE tries to make our reconstruction as accurate as possible</span>
    <span class="c1"># KLD tries to push the distributions as close as possible to unit Gaussian</span>
    <span class="k">return</span> <span class="n">BCE</span> <span class="o">+</span> <span class="n">KLD</span>

<span class="c1"># Dr Diederik Kingma: as if VAEs weren't enough, he also gave us Adam!</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="c1"># toggle model to train mode</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># in the case of MNIST, len(train_loader.dataset) is 60000</span>
    <span class="c1"># each `data` is of BATCH_SIZE samples and has shape [128, 1, 28, 28]</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">CUDA</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># push whole batch of data through VAE.forward() to get recon_loss</span>
        <span class="n">recon_batch</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># calculate scalar loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">recon_batch</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="c1"># calculate the gradient of the loss w.r.t. the graph leaves</span>
        <span class="c1"># i.e. input variables -- by the power of pytorch!</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="n">LOG_INTERVAL</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">'Train Epoch: {} [{}/{} ({:.0f}%)]</span><span class="se">\t</span><span class="s1">Loss: {:.6f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
                <span class="mf">100.</span> <span class="o">*</span> <span class="n">batch_idx</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">'====&gt; Epoch: {} Average loss: {:.4f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
          <span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="c1"># toggle model to test / inference mode</span>
    <span class="n">model</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># each data is of BATCH_SIZE (default 128) samples</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">CUDA</span><span class="p">:</span>
            <span class="c1"># make sure this lives on the GPU</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="c1"># we're only going to infer, so no autograd at all required: volatile=True</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">volatile</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">recon_batch</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">recon_batch</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
          <span class="n">n</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">8</span><span class="p">)</span>
          <span class="c1"># for the first 128 batch of the epoch, show the first 8 input digits</span>
          <span class="c1"># with right below them the reconstructed output digits</span>
          <span class="n">comparison</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">data</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span>
                                  <span class="n">recon_batch</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)[:</span><span class="n">n</span><span class="p">]])</span>
          <span class="n">save_image</span><span class="p">(</span><span class="n">comparison</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>
                     <span class="s1">'results/reconstruction_'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'.png'</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">'====&gt; Test set loss: {:.4f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_loss</span><span class="p">))</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">EPOCHS</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="n">test</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

    <span class="c1"># 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST</span>
    <span class="c1"># digits in latent space</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">ZDIMS</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">CUDA</span><span class="p">:</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

    <span class="c1"># save out as an 8x8 matrix of MNIST digits</span>
    <span class="c1"># this will give you a visual idea of how well latent space can generate things</span>
    <span class="c1"># that look like digits</span>
    <span class="n">save_image</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
               <span class="s1">'results/sample_'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'.png'</span><span class="p">)</span></code></pre></td></tr></tbody></table>
</div>
</div>
    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="https://vxlabs.com/tags/autoencoders/">autoencoders</a>
          <a href="https://vxlabs.com/tags/deep-learning/">deep learning</a>
          <a href="https://vxlabs.com/tags/neural-networks/">neural networks</a>
          <a href="https://vxlabs.com/tags/pytorch/">pytorch</a>
          <a href="https://vxlabs.com/tags/variational-autoencoders/">variational autoencoders</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="https://vxlabs.com/2018/01/31/creating-a-django-migration-for-a-gist-gin-index-with-a-special-index-operator/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Creating a Django migration for a GiST / GIN index with a special index operator.</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="https://vxlabs.com/2017/12/06/how-to-debug-pyinstaller-dll-pyd-load-failed-issues-on-windows/">
            <span class="next-text nav-default">How to debug PyInstaller DLL / PYD load failed issues on Windows</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        


<div style="font-size: 14px; color: #8a8a8a">
  Related posts:
  
  <a style="font-size: 14px; color: #8a8a8a" href="https://vxlabs.com/2017/03/17/miniconda3-tensorflow-keras-on-google-compute-engine-gpu-instance-the-step-by-step-guide/">🌤 Miniconda3, TensorFlow, Keras on Google Compute Engine GPU instance: The step-by-step guide.</a>
  
</div>




    
    <script data-isso="//vxlabs.com/isso" data-isso-reply-notifications="true" data-isso-avatar="false" data-isso-gravatar="true" data-isso-max-comments-nested="inf" data-isso-max-comments-top="inf" data-isso-require-email="true" src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/embed.min.js.다운로드"></script>

    
    
    <section data-title="Variational Autoencoder in PyTorch, commented and annotated." id="isso-thread"><h4>No Comments Yet</h4><div class="isso-postbox"><div class="form-wrapper"><div class="textarea-wrapper"><div contenteditable="true" class="textarea placeholder">Type Comment Here (at least 3 chars)</div><div class="preview"><div class="isso-comment"><div class="text-wrapper"><div class="text"></div></div></div></div></div><section class="auth-section"><p class="input-wrapper"><input type="text" name="author" placeholder="Name (optional)" value=""></p><p class="input-wrapper"><input type="email" name="email" placeholder="E-mail" value=""></p><p class="input-wrapper"><input type="text" name="website" placeholder="Website (optional)" value=""></p><p class="post-action"><input type="submit" value="Submit"></p><p class="post-action"><input type="button" name="preview" value="Preview"></p><p class="post-action"><input type="button" name="edit" value="Edit"></p></section><section class="notification-section" style="display: none;"><label><input type="checkbox" name="notification">Subscribe to email notification of replies</label></section></div></div><div id="isso-root"></div></section>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://vxlabs.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io/">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    © 
     - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Charl P. Botha</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script type="text/javascript" src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/jquery-3.2.1.min.js.다운로드"></script>
  <script type="text/javascript" src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/slideout-1.0.1.min.js.다운로드"></script>
  
<script type="text/javascript" src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/even.26188efa.min.js.다운로드"></script>
  <script type="text/javascript">
    window.MathJax = {
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script async="" src="./Variational Autoencoder in PyTorch, commented and annotated. - vxlabs_files/MathJax.js.다운로드" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>










</body></html>