plot(fit.pruned);text(fit.pruned)
fit = tree(variety ~., data=iris, split="deviance")
fit
summary(fit)
plot(fit);  text(fit)
cv.fit = cv.tree(fit, FUN=prune.misclass)
names(cv.fit)
cv.fit
par(mfrow=c(2,2))
plot(cv.fit$size,cv.fit$dev, type="b")
plot(cv.fit$k,cv.fit$dev, type="b")
fit.pruned = prune.misclass(fit, best=5)
plot(fit.pruned);text(fit.pruned)
fit.pruned = prune.misclass(fit, best=cv.fit$size[which.min(cv.fit$dev)])
plot(fit.pruned);text(fit.pruned)
pred = predict(fit.pruned, newdata=iris, type="class") #prediction
ctable = table(iris$variety, pred, dnn=c("Actual", "Predicted")); ctable #classification table
miss.err = 1-sum(diag(ctable))/sum(ctable); miss.err # Misclassification Rate
pred.acc = 1 - miss.err; pred.acc #Prediction Accuracy
diag(ctable)[2]/apply(ctable, 1, sum)[2] # Sensitivity
diag(ctable)[1]/apply(ctable, 1, sum)[1] # Specificity
pred2 = predict(fit.pruned, newdata=iris, type="class") #prediction  # fit.pruned ?? ??��
pred = prediction(pred2[,2], german$y)
pred = prediction(pred2[,2], iris$variety)
pred2 = predict(fit.pruned, newdata=iris, type="class") #prediction  # fit.pruned ?? ??��
pred = prediction(pred2[,2], iris$variety)
pred2
pred2 = predict(fit.pruned, newdata=iris, type="vector") #prediction  # fit.pruned ?? ??��
pred = prediction(pred2[,2], iris$variety)
pred2
#install.packages("ROCR")
library(ROCR)
### Split Data
iris.train <- iris1[sample(1:150, 100),]
### Split Data
a<-sample(1:150, 100)
iris.train <- iris1[a,]
iris.test <- iris1[-a,]
### Model fit(Full)
fit = multinom(variety ~., data = iris.train)
summary(fit)
### Model selection
fit2 = step(fit, direction = "both")
summary(fit2)
a
### Prediction
iris1[-a, 7] = predict(fit2,iris.test,type = "class")
iris1[-a, 8] = predict(fit2,iris1,type = "class")
iris1[-a, 8] = predict(fit2,iris.test,type = "class")
### Prediction
iris1[-a, 7] = predict(fit2,iris.test,type = "class")
iris1[-a, 8] = predict(fit2,iris.test,type = "class")
head(iris1)
iris <- read.csv("iris.csv",header=T)
iris1 <- iris
iris1$variety <- as.factor(iris1$variety)
### Data exploration
str(iris1)
### Split Data
a<-sample(1:150, 100)
iris.train <- iris1[a,]
iris.test <- iris1[-a,]
### Model fit(Full)
fit = multinom(variety ~., data = iris.train)
summary(fit)
### Model selection
fit2 = step(fit, direction = "both")
summary(fit2)
### Prediction
iris1[-a, 7] = predict(fit2,iris.test,type = "class")
iris1[-a, 8] = predict(fit2,iris.test,type = "class")
### Prediction
iris1[-a, 7] <- predict(fit2,iris.test,type = "class")
iris1[-a, 8] -< predict(fit2,iris.test,type = "class")
head(iris1)
### Prediction
iris1$full <- factor()
View(iris1)
iris1$full[-a] <- predict(fit2,iris.test,type = "class")
iris1$predict2 = predict(fit2,iris.test,type = "class")
### Prediction
iris.test$predict1 = predict(fit2,iris.test,type = "class")
iris.test$predict2 = predict(fit2,iris.test,type = "class")
head(iris.test)
t1<-table(iris1$variety,iris1$predict1)
t1<-table(iris.test$variety,iris.test$predict1)
t2<-table(iris.test$variety,iris.test$predict2)
t2
miss.err = 1-sum(diag(t2))/sum(t2) # Misclassification Rate
miss.err
pred.acc = 1 - miss.err #Prediction Accuracy
pred.acc
### Prediction
#train
iris.train$reduce = predict(fit2,iris.train,type = "class")
train <- table(iris.train$variety,iris.train$reduce)
train
test
test<-table(iris.test$variety,iris.test$reduce)
test
#test
iris.test$reduce = predict(fit2,iris.test,type = "class")
head(iris.test)
test<-table(iris.test$variety,iris.test$reduce)
test
### Errors
#train
miss.err = 1-sum(diag(train))/sum(train) # Misclassification Rate
miss.err
pred.acc = 1 - miss.err #Prediction Accuracy
pred.acc
#test
miss.err = 1-sum(diag(test))/sum(test) # Misclassification Rate
miss.err
pred.acc = 1 - miss.err #Prediction Accuracy
pred.acc
V = 10 #V-fold CV
miss.err.train = 0
miss.err.test = 0
a
id = sample(1:V, nrow(iris1), replace = T)
id
for(i in 1:V) {
print(i)
iris.train = iris1[id != i,]
iris.test = iris1[id == i,]
fit = multinom(variety ~., data = iris.train)
fit2 = step(fit, direction = "both") #Stepwise variable selection
iris.train$reduce = predict(fit2,iris.train,type = "class")
train <- table(iris.train$variety,iris.train$reduce)
iris.test$reduce = predict(fit2,iris.test,type = "class")
test<-table(iris.test$variety,iris.test$reduce)
pred.train = predict(fit2, newdata=test.train, type="class")
miss.err.train.temp = 1-sum(diag(train))/sum(train)
miss.err.train = miss.err.train + miss.err.train.temp
pred.test = predict(fit2, newdata=test.test, type="class")
miss.err.test.temp = 1-sum(diag(test))/sum(test)
miss.err.train = miss.err.train + miss.err.test.temp
}
for(i in 1:V) {
print(i)
iris.train = iris1[id != i,]
iris.test = iris1[id == i,]
fit = multinom(variety ~., data = iris.train)
fit2 = step(fit, direction = "both") #Stepwise variable selection
iris.train$reduce = predict(fit2,iris.train,type = "class")
train <- table(iris.train$variety,iris.train$reduce)
iris.test$reduce = predict(fit2,iris.test,type = "class")
test<-table(iris.test$variety,iris.test$reduce)
pred.train = predict(fit2, newdata=iris.train, type="class")
miss.err.train.temp = 1-sum(diag(train))/sum(train)
miss.err.train = miss.err.train + miss.err.train.temp
pred.test = predict(fit2, newdata=iris.test, type="class")
miss.err.test.temp = 1-sum(diag(test))/sum(test)
miss.err.train = miss.err.train + miss.err.test.temp
}
cv.err.train = miss.err.train/ V # CV training error
cv.err.train
cv.err.test = miss.err.test/ V # CV test error
cv.err.test
V = 10 #V-fold CV
miss.err.train = 0
miss.err.test = 0
set.seed(1234)
id = sample(1:V, nrow(iris1), replace = T)
for(i in 1:V) {
print(i)
iris.train = iris1[id != i,]
iris.test = iris1[id == i,]
fit = multinom(variety ~., data = iris.train)
fit2 = step(fit, direction = "both") #Stepwise variable selection
iris.train$reduce = predict(fit2,iris.train,type = "class")
train <- table(iris.train$variety,iris.train$reduce)
iris.test$reduce = predict(fit2,iris.test,type = "class")
test<-table(iris.test$variety,iris.test$reduce)
pred.train = predict(fit2, newdata=iris.train, type="class")
miss.err.train.temp = 1-sum(diag(train))/sum(train)
miss.err.train = miss.err.train + miss.err.train.temp
pred.test = predict(fit2, newdata=iris.test, type="class")
miss.err.test.temp = 1-sum(diag(test))/sum(test)
miss.err.test = miss.err.train + miss.err.test.temp
}
cv.err.train = miss.err.train/ V # CV training error
cv.err.train
cv.err.test = miss.err.test/ V # CV test error
cv.err.test
### Prediction
pred = predict(fit.pruned, newdata=iris, type="class") #prediction
ctable = table(iris$variety, pred, dnn=c("Actual", "Predicted")); ctable #classification table
miss.err = 1-sum(diag(ctable))/sum(ctable); miss.err # Misclassification Rate
pred.acc = 1 - miss.err; pred.acc #Prediction Accuracy
diag(ctable)[2]/apply(ctable, 1, sum)[2] # Sensitivity
diag(ctable)[1]/apply(ctable, 1, sum)[1] # Specificity
iris.train = iris[ii,]
ii = which(id==1)
set.seed(123)
V = 2
n =  NROW(german)
id = sample(1:V, n, prob = c(0.7,0.3), replace = T) # Partitioning 7:3
n =  nrow(iris)
id = sample(1:V, n, prob = c(0.7,0.3), replace = T) # Partitioning 7:3
ii = which(id==1)
iris.train = iris[ii,]
iris.test  = iris[-ii,]
fit = tree(variety ~., iris.train)
fit
summary(fit)
plot(fit);  text(fit)
set.seed(3)
cv.fit = cv.tree(fit, FUN=prune.misclass)
names(cv.fit)
cv.fit
par(mfrow=c(2,2))
plot(cv.fit$size,cv.fit$dev, type="b")
plot(cv.fit$k,cv.fit$dev, type="b")
fit.pruned = prune.misclass(fit, best=cv.fit$size[which.min(cv.fit$dev)])
plot(fit.pruned);text(fit.pruned)
cutoff = 0.5
pred = predict(fit.pruned, newdata=german.test, type="vector") #prediction
pred = predict(fit.pruned, newdata=iris.test, type="class") #prediction
ctable = table(german.test$y, yhat, dnn=c("Actual", "Predicted")); ctable #classification table
ctable = table(iris.test$y, pred, dnn=c("Actual", "Predicted")); ctable #classification table
pred
ctable = table(iris.test$variety, pred, dnn=c("Actual", "Predicted")); ctable #classification table
V = 10 #V-fold CV
miss.err.train = 0
miss.err.test = 0
set.seed(12345)
id = sample(1:V, nrow(german), replace = T)
set.seed(12345)
id = sample(1:V, nrow(iris), replace = T)
for(i in 1:V) {
print(i)
iris.train = iris1[id != i,]
iris.test = iris1[id == i,]
fit = tree(variety ~., iris.train) #Growing
cv.fit = cv.tree(fit, FUN=prune.misclass)
tree.size.min.dev = cv.fit$size[which.min(cv.fit$dev)]
fit.pruned = prune.misclass(fit, best=tree.size.min.dev) # Pruning
pred = predict(fit.pruned, newdata=iris.train, type="classr") #prediction
ctable = table(iris.train$variety, pred, dnn=c("Actual", "Predicted"));
miss.err.train.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.train = miss.err.train + miss.err.train.temp
pred = predict(fit.pruned, newdata=iris.test, type="class") #prediction
ctable = table(iris.test$variety, pred, dnn=c("Actual", "Predicted"));
miss.err.test.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.test = miss.err.test + miss.err.test.temp
}
for(i in 1:V) {
print(i)
iris.train = iris1[id != i,]
iris.test = iris1[id == i,]
fit = tree(variety ~., iris.train) #Growing
cv.fit = cv.tree(fit, FUN=prune.misclass)
tree.size.min.dev = cv.fit$size[which.min(cv.fit$dev)]
fit.pruned = prune.misclass(fit, best=tree.size.min.dev) # Pruning
pred = predict(fit.pruned, newdata=iris.train, type="class") #prediction
ctable = table(iris.train$variety, pred, dnn=c("Actual", "Predicted"));
miss.err.train.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.train = miss.err.train + miss.err.train.temp
pred = predict(fit.pruned, newdata=iris.test, type="class") #prediction
ctable = table(iris.test$variety, pred, dnn=c("Actual", "Predicted"));
miss.err.test.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.test = miss.err.test + miss.err.test.temp
}
cv.err.train = miss.err.train/ V; cv.err.train # CV training error
cv.err.test = miss.err.test/ V;cv.err.test # CV test error
#install.packages("rpart")
#install.packages("adabag")
library(rpart)
library(adabag)
#install.packages("rpart")
install.packages("adabag")
#install.packages("rpart")
#install.packages("adabag")
library(rpart)
library(adabag)
set.seed(1234)
my.control = rpart.control(xval=0, cp=0, minsplit=5, maxdepth=10)
fit = bagging(variety~., data=iris, mfinal=50, control=my.control)
print(fit$importance)
importanceplot(fit)
pred = predict.bagging(fit, newdata=german)
pred = predict.bagging(fit, newdata=iris)
ctable = table(german$y, yhat, dnn=c("Actual", "Predicted")); ctable #classification table
ctable = table(iris$variety, pred, dnn=c("Actual", "Predicted")); ctable #classification table
pred
ctable = table(iris$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
miss.err = 1-sum(diag(ctable))/sum(ctable); miss.err # Misclassification Rate
pred.acc = 1 - miss.err; pred.acc #Prediction Accuracy
set.seed(1234)
my.control = rpart.control(xval=0, cp=0, minsplit=5, maxdepth=10)
fit = bagging(variety~., data=iris.train, mfinal=50, control=my.control)
print(fit$importance)
importanceplot(fit)
pred = predict.bagging(fit, newdata=iris.test)
ctable = table(iris.test$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
miss.err = 1-sum(diag(ctable))/sum(ctable); miss.err # Misclassification Rate
pred.acc = 1 - miss.err; pred.acc #Prediction Accuracy
V = 10 #V-fold CV
miss.err.train = 0
miss.err.test = 0
set.seed(12345)
id = sample(1:V, nrow(iris), replace = T)
for(i in 1:V) {
print(i)
iris.train = iris[id != i,]
iris.test = iris[id == i,]
my.control = rpart.control(xval=0, cp=0, minsplit=5, maxdepth=10)
fit = bagging(variety~., data=iris.train, mfinal=50, control=my.control)
pred = predict.bagging(fit, newdata=iris.train)
ctable = table(iris.train$variety, pred$class, dnn=c("Actual", "Predicted"))
miss.err.train.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.train = miss.err.train + miss.err.train.temp
pred = predict.bagging(fit, newdata=iris.test)
ctable = table(iris.test$variety, pred$class, dnn=c("Actual", "Predicted"))
miss.err.test.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.test = miss.err.test + miss.err.test.temp
}
cv.err.train = miss.err.train/ V; cv.err.train # CV training error
cv.err.test = miss.err.test/ V;cv.err.test # CV test error
set.seed(1234)
my.control = rpart.control(xval=0, cp=0, maxdepth=1)
fit = boosting(variety~., data=iris, boos=T, mfinal=50, control=my.control)
fit$trees
ctable = table(iris$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
pred = predict.boosting(fit, newdata=iris)
ctable = table(iris$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
miss.err = 1-sum(diag(ctable))/sum(ctable); miss.err # Misclassification Rate
pred.acc = 1 - miss.err; pred.acc #Prediction Accuracy
set.seed(123)
V = 2
n =  nrow(iris)
id = sample(1:V, n, prob = c(0.7,0.3), replace = T) # Partitioning 7:3
ii = which(id==1)
iris.train = iris[ii,]
iris.test  = iris[-ii,]
set.seed(1234)
my.control = rpart.control(xval=0, cp=0, maxdepth=1)
fit = boosting(variety~., data=iris.train, boos=T, mfinal=50, control=my.control)
ctable = table(iris.test$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
pred = predict.boosting(fit, newdata=iris.test)
ctable = table(iris.test$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
miss.err = 1-sum(diag(ctable))/sum(ctable); miss.err # Misclassification Rate
pred.acc = 1 - miss.err; pred.acc #Prediction Accuracy
diag(ctable)[2]/apply(ctable, 1, sum)[2] # Sensitivity
diag(ctable)[1]/apply(ctable, 1, sum)[1] # Specificity
for(i in 1:V) {
print(i)
iris.train = iris[id != i,]
iris.test = iris[id == i,]
my.control = rpart.control(xval=0, cp=0, maxdepth=1)
fit = boosting(variety~., data=iris.train, boos=T, mfinal=50, control=my.control)
pred = predict.boosting(fit, newdata=iris.train)
ctable = table(iris.train$variety, pred$class, dnn=c("Actual", "Predicted"))
miss.err.train.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.train = miss.err.train + miss.err.train.temp
pred = predict.boosting(fit, newdata=german.test)
ctable = table(iris.test$variety, pred$class, dnn=c("Actual", "Predicted"))
miss.err.test.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.test = miss.err.test + miss.err.test.temp
}
V = 10 #V-fold CV
miss.err.train = 0
miss.err.test = 0
set.seed(12345)
id = sample(1:V, nrow(iris), replace = T)
for(i in 1:V) {
print(i)
iris.train = iris[id != i,]
iris.test = iris[id == i,]
my.control = rpart.control(xval=0, cp=0, maxdepth=1)
fit = boosting(variety~., data=iris.train, boos=T, mfinal=50, control=my.control)
pred = predict.boosting(fit, newdata=iris.train)
ctable = table(iris.train$variety, pred$class, dnn=c("Actual", "Predicted"))
miss.err.train.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.train = miss.err.train + miss.err.train.temp
pred = predict.boosting(fit, newdata=german.test)
ctable = table(iris.test$variety, pred$class, dnn=c("Actual", "Predicted"))
miss.err.test.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.test = miss.err.test + miss.err.test.temp
}
for(i in 1:V) {
print(i)
iris.train = iris[id != i,]
iris.test = iris[id == i,]
my.control = rpart.control(xval=0, cp=0, maxdepth=1)
fit = boosting(variety~., data=iris.train, boos=T, mfinal=50, control=my.control)
pred = predict.boosting(fit, newdata=iris.train)
ctable = table(iris.train$variety, pred$class, dnn=c("Actual", "Predicted"))
miss.err.train.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.train = miss.err.train + miss.err.train.temp
pred = predict.boosting(fit, newdata=iris.test)
ctable = table(iris.test$variety, pred$class, dnn=c("Actual", "Predicted"))
miss.err.test.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.test = miss.err.test + miss.err.test.temp
}
cv.err.train = miss.err.train/ V; cv.err.train # CV training error
cv.err.test = miss.err.test/ V;cv.err.test # CV test error
#install.packages("randomForest")
library(randomForest)
set.seed(1234)
fit = randomForest(variety~., data=iris, ntree=100, mtry=5, importance=T)
fit = randomForest(variety~., data=iris, ntree=100, mtry=2, importance=T)
plot(fit, type="l")
importance(fit)
pred = predict(fit, newdata=iris, type="prob")
pred
pred = predict(fit, newdata=iris, type="class")
ctable = table(iris$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
pred = predict(fit, newdata=iris, type="class")
ctable = table(iris$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
ctable = table(iris$variety, pred, dnn=c("Actual", "Predicted")); ctable #classification table
miss.err = 1-sum(diag(ctable))/sum(ctable); miss.err # Misclassification Rate
pred.acc = 1 - miss.err; pred.acc #Prediction Accuracy
set.seed(1234)
fit = randomForest(variety~., data=variety.train, ntree=100, mtry=2, importance=T)
set.seed(123)
V = 2
n =  nrow(iris)
id = sample(1:V, n, prob = c(0.7,0.3), replace = T) # Partitioning 7:3
ii = which(id==1)
iris.train = iris[ii,]
iris.test  = iris[-ii,]
set.seed(1234)
fit = randomForest(variety~., data=iris.train, ntree=100, mtry=2, importance=T)
plot(fit, type="l")
importance(fit)
pred = predict(fit, newdata=iris.test, type="class")
ctable = table(iris.test$variety, pred, dnn=c("Actual", "Predicted")); ctable #classification table
miss.err = 1-sum(diag(ctable))/sum(ctable); miss.err # Misclassification Rate
pred.acc = 1 - miss.err; pred.acc #Prediction Accuracy
pred = predict(fit, newdata=iris.train, type="class")
V = 10 #V-fold CV
miss.err.train = 0
miss.err.test = 0
set.seed(12345)
id = sample(1:V, nrow(iris), replace = T)
for(i in 1:V) {
print(i)
iris.train = iris[id != i,]
iris.test = iris[id == i,]
fit = randomForest(variety~., data=iris.train, ntree=100, mtry=2, importance=T)
pred = predict(fit, newdata=iris.train, type="class")
ctable = table(iris.train$variety, pred, dnn=c("Actual", "Predicted"))
miss.err.train.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.train = miss.err.train + miss.err.train.temp
pred = predict(fit, newdata=iris.test, type="class")
ctable = table(iris.test$variety, pred, dnn=c("Actual", "Predicted"))
miss.err.test.temp = 1-sum(diag(ctable))/sum(ctable)
miss.err.test = miss.err.test + miss.err.test.temp
}
cv.err.train = miss.err.train/ V; cv.err.train # CV training error
cv.err.test = miss.err.test/ V;cv.err.test # CV test error
set.seed(1234)
my.control = rpart.control(xval=0, cp=0, minsplit=5, maxdepth=10)
fit = bagging(variety~., data=iris, mfinal=50, control=my.control)
print(fit$importance)
importanceplot(fit)
pred = predict.bagging(fit, newdata=iris)
ctable = table(iris$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
miss.err = 1-sum(diag(ctable))/sum(ctable); miss.err # Misclassification Rate
pred.acc = 1 - miss.err; pred.acc #Prediction Accuracy
set.seed(123)
#install.packages("rpart")
#install.packages("adabag")
library(rpart)
library(adabag)
set.seed(1234)
my.control = rpart.control(xval=0, cp=0, minsplit=5, maxdepth=10)
fit = bagging(variety~., data=iris, mfinal=50, control=my.control)
iris <- read.csv("iris.csv",header=T)
my.control = rpart.control(xval=0, cp=0, minsplit=5, maxdepth=10)
fit = bagging(variety~., data=iris, mfinal=50, control=my.control)
print(fit$importance)
importanceplot(fit)
pred = predict.bagging(fit, newdata=iris)
ctable = table(iris$variety, pred$class, dnn=c("Actual", "Predicted")); ctable #classification table
fit.pruned = prune.misclass(fit, best=5)
cv.fit = cv.tree(fit, FUN=prune.misclass)
#install.packages("tree")
library(tree)
fit = tree(variety ~., data=iris, split="deviance")
fit
summary(fit)
plot(fit);  text(fit)
cv.fit = cv.tree(fit, FUN=prune.misclass)
names(cv.fit)
cv.fit
plot(cv.fit$size,cv.fit$dev, type="b")
plot(cv.fit$k,cv.fit$dev, type="b")
fit.pruned = prune.misclass(fit, best=5)
plot(fit.pruned);text(fit.pruned)
fit.pruned = prune.misclass(fit, best=cv.fit$size[which.min(cv.fit$dev)])
plot(fit.pruned);text(fit.pruned)
?prune.misclass
fit
plot
plot(fit)
set.seed(1234)
fit = randomForest(variety~., data=iris, ntree=100, mtry=2, importance=T)
#install.packages("randomForest")
library(randomForest)
set.seed(1234)
fit = randomForest(variety~., data=iris, ntree=100, mtry=2, importance=T)
plot(fit, type="l")
importance(fit)
fit
str(fit)
?randomForest
plot(fit, type="l")
colnames(fit$err.rate)
